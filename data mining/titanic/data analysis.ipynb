{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked  Survived\n",
      "0       3    male  22.0      1      0   7.2500        S         0\n",
      "1       1  female  38.0      1      0  71.2833        C         1\n",
      "2       3  female  26.0      0      0   7.9250        S         1\n",
      "3       1  female  35.0      1      0  53.1000        S         1\n",
      "4       3    male  35.0      0      0   8.0500        S         0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Re-importing the data to ensure correct DataFrame types\n",
    "train_data = pd.read_csv(r'C:\\Users\\Shrey\\OneDrive\\Desktop\\data mining\\train.csv')\n",
    "test_data = pd.read_csv(r'C:\\Users\\Shrey\\OneDrive\\Desktop\\data mining\\test.csv')\n",
    "\n",
    "# Dropping the unnecessary columns from test_data\n",
    "test_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "# Verifying data types\n",
    "print(type(train_data))  # Should output: <class 'pandas.core.frame.DataFrame'>\n",
    "print(type(test_data))   # Should output: <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "# Selecting features and making sure that `train_data` and `test_data` remain DataFrames\n",
    "selected_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "\n",
    "# Selecting columns\n",
    "train_data = train_data[selected_features + ['Survived']]\n",
    "test_data = test_data[selected_features]\n",
    "\n",
    "# Displaying the first few rows to ensure correct selection\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass        0\n",
      "Sex           0\n",
      "Age         177\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Fare          0\n",
      "Embarked      2\n",
      "Survived      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age'] = pd.to_numeric(train_data['Age'], errors='coerce')\n",
    "\n",
    "train_data['Age'].fillna(train_data['Age'].median(), inplace=True)\n",
    "\n",
    "train_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "test_data['Age'].fillna(test_data['Age'].median(), inplace=True)\n",
    "test_data['Embarked'].fillna(test_data['Embarked'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "Survived    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass   Age  SibSp  Parch     Fare  Survived  Sex_male  Embarked_Q  \\\n",
      "0       3  22.0      1      0   7.2500         0         1           0   \n",
      "1       1  38.0      1      0  71.2833         1         0           0   \n",
      "2       3  26.0      0      0   7.9250         1         0           0   \n",
      "3       1  35.0      1      0  53.1000         1         0           0   \n",
      "4       3  35.0      0      0   8.0500         0         1           0   \n",
      "\n",
      "   Embarked_S  \n",
      "0           1  \n",
      "1           0  \n",
      "2           1  \n",
      "3           1  \n",
      "4           1  \n"
     ]
    }
   ],
   "source": [
    "train_data = pd.get_dummies(train_data, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SibSp  Parch  FamilySize\n",
      "0      1      0           2\n",
      "1      1      0           2\n",
      "2      0      0           1\n",
      "3      1      0           2\n",
      "4      0      0           1\n"
     ]
    }
   ],
   "source": [
    "train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "\n",
    "print(train_data[['SibSp', 'Parch', 'FamilySize']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass   Age  SibSp  Parch     Fare  Survived  Sex_male  Embarked_Q  \\\n",
      "0       3  22.0      1      0   7.2500         0         1           0   \n",
      "1       1  38.0      1      0  71.2833         1         0           0   \n",
      "2       3  26.0      0      0   7.9250         1         0           0   \n",
      "3       1  35.0      1      0  53.1000         1         0           0   \n",
      "4       3  35.0      0      0   8.0500         0         1           0   \n",
      "\n",
      "   Embarked_S  FamilySize  \n",
      "0           1           2  \n",
      "1           0           2  \n",
      "2           1           1  \n",
      "3           1           2  \n",
      "4           1           1  \n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age AgeBin\n",
      "0  22.0      2\n",
      "1  38.0      2\n",
      "2  26.0      2\n",
      "3  35.0      2\n",
      "4  35.0      2\n"
     ]
    }
   ],
   "source": [
    "train_data['AgeBin'] = pd.cut(train_data['Age'], bins=[0, 12, 18, 60, 80], labels=[0, 1, 2, 3])\n",
    "test_data['AgeBin'] = pd.cut(test_data['Age'], bins=[0, 12, 18, 60, 80], labels=[0, 1, 2, 3])\n",
    "\n",
    "print(train_data[['Age', 'AgeBin']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_data.drop('Survived', axis=1)\n",
    "y = train_data['Survived']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7988826815642458\n",
      "[[89 16]\n",
      " [20 54]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Splitting the data\n",
    "X = train_data.drop('Survived', axis=1)\n",
    "y = train_data['Survived']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Train the model with increased max_iter\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       105\n",
      "           1       0.77      0.73      0.75        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.79      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
